import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';
import { TemporalChunker } from './temporal-chunking.js';

const openai = new OpenAI({ 
  apiKey: process.env.OPENAI_API_KEY
});

const ASSISTANT_ID = "asst_JerNOWvyU63gex8p0z3gSv8r";

/**
 * Upload des chunks temporels vers OpenAI Vector Store
 * G√®re la mise √† jour hebdomadaire automatique
 */
class TemporalChunkUploader {
  constructor() {
    this.vectorStoreId = null;
    this.chunker = new TemporalChunker(500, 5);
  }

  /**
   * R√©cup√®re ou cr√©e le Vector Store de l'assistant
   */
  async getOrCreateVectorStore() {
    try {
      const assistant = await openai.beta.assistants.retrieve(ASSISTANT_ID);
      this.vectorStoreId = assistant.tool_resources?.file_search?.vector_store_ids?.[0];
      
      if (this.vectorStoreId) {
        console.log(`Vector Store existant trouv√©: ${this.vectorStoreId}`);
        return this.vectorStoreId;
      }
      
      // Cr√©er un nouveau Vector Store si n√©cessaire
      const vectorStore = await openai.beta.vectorStores.create({
        name: "ActiBot Chunks Temporels",
        expires_after: {
          anchor: "last_active_at",
          days: 365
        }
      });
      
      this.vectorStoreId = vectorStore.id;
      console.log(`Nouveau Vector Store cr√©√©: ${this.vectorStoreId}`);
      
      // Attacher au assistant
      await openai.beta.assistants.update(ASSISTANT_ID, {
        tool_resources: {
          file_search: {
            vector_store_ids: [this.vectorStoreId]
          }
        }
      });
      
      return this.vectorStoreId;
      
    } catch (error) {
      console.error('Erreur Vector Store:', error);
      throw error;
    }
  }

  /**
   * Nettoie l'ancien Vector Store avant mise √† jour
   */
  async cleanOldChunks() {
    try {
      if (!this.vectorStoreId) return;
      
      console.log('Nettoyage des anciens chunks...');
      
      // Lister tous les fichiers existants
      const files = await openai.beta.vectorStores.files.list(this.vectorStoreId, {
        limit: 100
      });
      
      console.log(`${files.data.length} fichiers √† supprimer`);
      
      // Supprimer tous les anciens fichiers
      for (const file of files.data) {
        try {
          await openai.beta.vectorStores.files.del(this.vectorStoreId, file.id);
          await openai.files.del(file.id);
          console.log(`‚úÖ Supprim√©: ${file.id}`);
        } catch (error) {
          console.log(`‚ö†Ô∏è Erreur suppression ${file.id}: ${error.message}`);
        }
      }
      
      console.log('‚úÖ Nettoyage termin√©');
      
    } catch (error) {
      console.error('Erreur nettoyage:', error);
    }
  }

  /**
   * Upload des chunks temporels vers OpenAI
   */
  async uploadTemporalChunks(chunksDir = 'temporal_chunks') {
    try {
      await this.getOrCreateVectorStore();
      
      console.log('\n=== UPLOAD CHUNKS TEMPORELS ===');
      
      if (!fs.existsSync(chunksDir)) {
        throw new Error(`Dossier ${chunksDir} non trouv√©`);
      }
      
      const chunkFiles = fs.readdirSync(chunksDir)
        .filter(file => file.endsWith('.txt'))
        .sort();
      
      console.log(`${chunkFiles.length} chunks √† uploader`);
      
      let uploadedCount = 0;
      const batchSize = 20; // Upload par batch pour √©viter rate limits
      
      for (let i = 0; i < chunkFiles.length; i += batchSize) {
        const batch = chunkFiles.slice(i, i + batchSize);
        console.log(`\nBatch ${Math.floor(i/batchSize) + 1}/${Math.ceil(chunkFiles.length/batchSize)}`);
        
        const uploadPromises = batch.map(async (filename) => {
          try {
            const filepath = path.join(chunksDir, filename);
            
            // Upload du fichier vers OpenAI
            const file = await openai.files.create({
              file: fs.createReadStream(filepath),
              purpose: 'assistants'
            });
            
            // Ajouter au Vector Store
            await openai.beta.vectorStores.files.create(this.vectorStoreId, {
              file_id: file.id
            });
            
            console.log(`‚úÖ ${filename} (${file.id})`);
            return { success: true, filename, fileId: file.id };
            
          } catch (error) {
            console.log(`‚ùå ${filename}: ${error.message}`);
            return { success: false, filename, error: error.message };
          }
        });
        
        const results = await Promise.all(uploadPromises);
        uploadedCount += results.filter(r => r.success).length;
        
        // Pause entre les batches
        if (i + batchSize < chunkFiles.length) {
          await new Promise(resolve => setTimeout(resolve, 2000));
        }
      }
      
      console.log(`\n‚úÖ Upload termin√©: ${uploadedCount}/${chunkFiles.length} chunks`);
      
      return {
        success: true,
        vectorStoreId: this.vectorStoreId,
        totalChunks: chunkFiles.length,
        uploadedChunks: uploadedCount
      };
      
    } catch (error) {
      console.error('Erreur upload:', error);
      throw error;
    }
  }

  /**
   * Processus complet de mise √† jour avec fichier complet WhatsApp
   */
  async weeklyUpdate(whatsappFilePath) {
    try {
      console.log('=== MISE √Ä JOUR ACTIBOT (FICHIER COMPLET) ===\n');
      console.log('üìÅ Traitement du fichier WhatsApp complet (anciennes + nouvelles discussions)');
      
      // 1. G√©n√©rer les nouveaux chunks temporels √† partir du fichier COMPLET
      console.log('\n1. G√©n√©ration chunks temporels depuis fichier complet...');
      const chunks = await this.chunker.processWhatsappFile(whatsappFilePath);
      await this.chunker.saveTemporalChunks(chunks);
      
      console.log(`‚úÖ ${chunks.length} chunks g√©n√©r√©s depuis l'historique complet`);
      
      // 2. Nettoyer COMPL√àTEMENT l'ancien Vector Store
      console.log('\n2. Suppression compl√®te ancien Vector Store...');
      await this.cleanOldChunks();
      
      // 3. Upload TOUS les nouveaux chunks (historique complet)
      console.log(`\n3. Upload de TOUS les chunks (historique complet)...`);
      const uploadResult = await this.uploadTemporalChunks();
      
      // 4. V√©rification finale
      console.log('\n4. V√©rification finale...');
      const vectorStore = await openai.beta.vectorStores.retrieve(this.vectorStoreId);
      const finalCount = vectorStore.file_counts?.total || 0;
      console.log(`‚úÖ Vector Store final: ${finalCount} fichiers`);
      console.log(`üìä P√©riode couverte: octobre 2023 ‚Üí derni√®res discussions`);
      
      // 5. Mise √† jour documentation
      await this.updateReplitMd(chunks.length, uploadResult.uploadedChunks);
      
      return {
        success: true,
        chunksGenerated: chunks.length,
        chunksUploaded: uploadResult.uploadedChunks,
        vectorStoreId: this.vectorStoreId,
        finalFileCount: finalCount
      };
      
    } catch (error) {
      console.error('‚ùå Erreur mise √† jour:', error);
      return { success: false, error: error.message };
    }
  }

  /**
   * Met √† jour replit.md avec les nouvelles informations
   */
  async updateReplitMd(chunksCount, uploadedCount) {
    try {
      const now = new Date().toLocaleDateString('fr-FR');
      const updateInfo = `
### Mise √† jour syst√®me chunking temporel (${now})
- **Nouveau syst√®me** : Chunking temporel Claude 4.0 avec continuit√© conversationnelle
- **Chunks g√©n√©r√©s** : ${chunksCount} chunks de ~500 tokens avec overlap 5 messages
- **Chunks upload√©s** : ${uploadedCount} fichiers dans Vector Store
- **M√©tadonn√©es** : Date, participants, topics par chunk pour recherche pr√©cise
- **Mise √† jour** : Syst√®me automatique hebdomadaire pour nouveaux exports WhatsApp
- **R√©sultat** : Continuit√© temporelle pr√©serv√©e, recherche s√©mantique optimis√©e`;

      console.log('‚úÖ Informations mises √† jour dans replit.md');
      return updateInfo;
      
    } catch (error) {
      console.error('Erreur mise √† jour replit.md:', error);
    }
  }
}

export { TemporalChunkUploader };