=== M√âTADONN√âES CHUNK ===
P√©riode: null ‚Üí null
Participants: 
Topics: 
Tokens: 540
Messages: 6

=== CONTENU ===
Gardons un espoir : si les LLMs vont buter contre un mur (manque de data, limites de cette architecture) alors on verra apparaitre une autre architecture qui pourrait etre plus vertueuse !
19/02/2025, 10:02 - Jean-Marc Everard: Oui en effet, on peut l'esp√©rer. En attendant, chaque fois que j'(en ai l'occasion et singuli√®rement dans les conf√©rences ou formations que je donne, j'ai toujours un moment de sensibilisation √† ces aspects en expliquant l'impact du choix des mod√®les, ne pas utiliser l'IA inutilement ou pour des choses que l'on pourrait faire tout aussi bien et aussi vite sans etc... C'est presque de l'"√©vang√©lisation". Mais dans le m√™me temps je n'h√©site pas trop √† garder quelques effets "waouw", donc je sais que c'est un peu contradictoire et paradoxale (je dois avoir une dissonnance cognitive avec √ßa üòâ). Mais bon, j'essaie de les g√©n√©rer avec des mod√®les en local sur ma machine. Il faut aussi dire qu'il n'y a pas que l'IA Gen et que d'ailleurs les autres IA plus discr√®tes sont souvent plus utiles au final. Bref, cultivons l'esprit critique.
19/02/2025, 10:23 - Francois Bocquet: J‚Äôai un √©norme doute sur le fait que faire tourner des mod√®les localement sur sa propre machine co√ªte moins cher en √©nergie que de le faire sur des serveurs d√©di√©s et optimis√©s dans des data center optimis√©s (refroidissement et √©nergie renouvelable). Quelqu‚Äôun aurait il des donn√©es sur cette question ? Mon intuition c‚Äôest que faire tourner des mod√®les localement co√ªte plus cher et est moins performant que de les faire tourner sur des infrastructures d√©di√©es. √áa oblige √† avoir des machines surpuissantes et tr√®s co√ªteuses √† l‚Äôachat comme en √©nergie et √† d√©velopper des comp√©tences sp√©cifiques.
19/02/2025, 10:26 - Rochane: int√©ressant car tu tords le cou √† certaines croyances. Ce serait cool de trouver une √©tude √† ce sujet
19/02/2025, 10:28 - +32 483 60 53 96: J'esp√®re avoir quelques donn√©es l√† dessus courant mars (comparer comparia et des modeles sur ordinateur avec codecarbone?)
LM Studio mont r√©pondu et √† ce niveau ils n'ont pas bcp de documentation √† partager. J'imagine ca d√©pend tellement de ce qu'on cherche √† faire et avec quel mod√®le.