=== MÃ‰TADONNÃ‰ES CHUNK ===
PÃ©riode: null â†’ null
Participants: 
Topics: 
Tokens: 504
Messages: 14

=== CONTENU ===
Au sommaire de cette revue mÃ©diation et mediations - teluq - octobre 24 :
- Le dÃ©veloppement professionnel des enseignants Ã  et avec lâ€™intelligence artificielle : une revue de littÃ©rature
- Gouverner lâ€™Ã©cole Ã  lâ€™heure de lâ€™IA : synthÃ¨se des connaissances sur la gouvernance scolaire basÃ©e sur les donnÃ©es
- ChatGPT : quel en a Ã©tÃ© lâ€™usage spontanÃ© dâ€™Ã©tudiants de premiÃ¨re annÃ©e universitaire Ã  son arrivÃ©e?
- Ã‰laboration et validation dâ€™un rÃ©fÃ©rentiel Ã©thique de lâ€™intelligence artificielle en Ã‰ducation : cas du contexte marocain
- Perceptions et usages dâ€™un chatbot comme tuteur de cours en sciences de lâ€™Ã©ducation
- Les dÃ©fis de lâ€™IA dans lâ€™Ã©ducation : de la protection des donnÃ©es aux biais algorithmiques
- Les transformations Ã©ducatives Ã  lâ€™Ã¨re de lâ€™intelligence artificielle : entretien avec le professeur AdÄ±gÃ¼zel
07/11/2024, 19:17 - +33 6 46 86 16 67: Bonjour ! Dans la formation que jâ€™anime on prend un peu de distance sur lâ€™humanisation de lâ€™IA. Des collÃ¨gues ont sorti cet article : https://www.epsiloon.com/tous-les-numeros/n39/ia_et_maintenant_elle_nous_ment/ je vais creuser mais je voulais un peu votre avis ğŸ˜
07/11/2024, 19:24 - +33 6 71 11 12 91: Je suis quelque peu dubitatif sur cet article, qui dit d'une part "En fait, nous ne comprenons pas bien les processus de dÃ©cision interne des grands modÃ¨les de langage." et ailleurs "En regardant dans les Ã©tats internes des algorithmes, nous constatons quâ€™ils savent ce qui est vrai et quâ€™ils ont choisi de dire dÃ©libÃ©rÃ©ment quelque chose de faux".
On ne comprend pas mais on comprend tout, cela me rappelle la rhÃ©torique de Trump, une rÃ©fÃ©rence dans la vÃ©ritÃ© scientifique (alternative)...
Machiavel, je te vois ! ğŸ˜‚
07/11/2024, 19:44 - â€+33 6 82 82 74 21 a ajoutÃ© +33 7 57 02 28 21
07/11/2024, 19:50 - Rochane: J'ai lu dans un autre article que les chercheurs combattent les mensonges des IA via la dÃ©tection d'anomalies, l'explicabilitÃ© des systÃ¨mes, des tests rigoureux et un encadrement rÃ©glementaire strict des modÃ¨les Ã  haut risque.